{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f92ad1-7a55-4db9-afcb-4657bb6503d7",
   "metadata": {},
   "source": [
    "### Word Sense Disambiguation (WSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf649d3-6ac5-4635-9660-d7627f57eb96",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a2ea9f-dc72-44fe-98b8-3bd9207c28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9acbfc-bd7d-4dd5-8643-eccb6a10d53b",
   "metadata": {},
   "source": [
    "##### Set up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e13b0a-a3a9-4731-8f7c-d84e4638348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='decision-list-log.txt',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fe009-a6fb-4f5e-bbd3-e30c40398223",
   "metadata": {},
   "source": [
    "#### decision-list.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39986ecf-07ad-482b-a08d-11d5a77886e0",
   "metadata": {},
   "source": [
    "##### Algorithm:\n",
    "\n",
    "1. Read the XML files (TRAIN_XML and TEST_XML) and define the output file paths (OUTPUT and OUTPUT_ANSWERS).\n",
    "2. Define a set of feature functions in the feature_set() function. These functions extract specific patterns from a line and associate them with a sense. Additional feature functions can be added as needed.\n",
    "3. Implement a probability() function that calculates the probability of an attribute occurring in the sense_text and other_text.\n",
    "4. Read the training XML file (TRAIN_XML) using BeautifulSoup and create an attribute list by identifying patterns from line-train.xml and associating attributes with sense. This is done by iterating over the instances in the XML file and extracting the relevant text based on the sense.\n",
    "5. Read the testing XML file (TEST_XML) using BeautifulSoup and initialize variables for counting the occurrences of \"phone\" and \"product\" senses.\n",
    "6. Calculate the probability for each attribute in the attribute list by calling the probability() function. The probabilities are written to the OUTPUT file.\n",
    "7. Sort the attribute_list based on their probability scores to create a decision list.\n",
    "8. Determine the default sense based on the counts of \"phone\" and \"product\" senses in the training data.\n",
    "9. Iterate over the instances in the testing XML file and extract the context. For each context, perform a search on a particular attribute in the context by iterating over the attribute_list and checking if the attribute matches the context.\n",
    "10. If a match is found, assign the associated sense to the instance. If no match is found, assign the default sense.\n",
    "11. Write the assigned senses to the OUTPUT_ANSWERS file in the required format.\n",
    "12. Print the assigned senses in the same format as the gold standard file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff592df1-9cf8-4c18-8343-c8d62ea222d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer instance=\"line-n.w8_059:8174:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_098:12684:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_106:13309:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_40:10187:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_16:217:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_119:16927:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_008:13756:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_041:15186:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 05601797:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_119:2964:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_040:13652:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_122:2194:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 45903907:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 43602625:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_034:3995:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_139:696:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 20801955:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_028:3156:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 19600919:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_111:8071:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_041:4840:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_074:3928:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_049:15000:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_086:3306:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_8:1533:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_042:5289:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_041:11151:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_059:9261:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_6:10969:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 41702230:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_004:1365:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 26902918:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 37804749:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_6:2907:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_106:10827:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 02400926:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_107:12000:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_087:620:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 30203503:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_40:10216:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 24500349:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 02200986:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_024:3051:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_023:17827:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_142:13364:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_083:14895:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_117:10197:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_013:14047:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_019:14634:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_017:6376:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 24900680:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_021:3496:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_13:9355:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_098:13314:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_064:14051:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_107:7711:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_40:10241:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_111:6250:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_31:14204:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_20:7066:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_027:13714:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_006:6674:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_080:1471:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_124:728:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_083:9304:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_019:4936:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_17:14207:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_093:5547:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_085:427:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_112:2163:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_115:6602:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_081:8566:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_104:2916:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_050:15645:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_033:3398:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_8:3899:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 37805623:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_016:14692:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_107:826:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_002:18532:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_102:12660:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_002:7541:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_063:10855:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 18601882:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_7:13171:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_32:1867:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_29:3437:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_019:18445:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 45700442:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_067:14552:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_053:16416:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_12:680:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_8:1503:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_066:3322:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_100:4429:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_104:8687:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 54101892:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_038:1345:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_126:14239:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_30:3935:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_18:11863:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_003:16519:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.art7} aphb 29604729:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_38:10638:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_046:6144:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_098:14382:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_074:4317:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_011:18280:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_053:3883:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_040:16402:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_065:13727:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_007:14740:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_011:260:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_003:8955:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_011:298:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_122:11595:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w9_1:4358:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_108:11591:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_065:17112:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_070:8114:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_011:13061:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_100:15579:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_071:6321:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w8_110:14049:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_108:4296:\" senseid=\"product\"/>\n",
      "<answer instance=\"line-n.w7_057:1203:\" senseid=\"product\"/>\n"
     ]
    }
   ],
   "source": [
    "# Run %%writefile decision-list.py to write and save decision-list.py\n",
    "\n",
    "# Input files\n",
    "TRAIN_XML = r\"C:\\Users\\muge\\Github\\line-data\\line-train.xml\"\n",
    "TEST_XML = r\"C:\\Users\\muge\\Dropbox\\GMU\\AIT 526\\Module 7\\line-data\\line-test.xml\"\n",
    "OUTPUT = r\"C:\\Users\\muge\\Dropbox\\GMU\\AIT 526\\Module 7\\line-data\\my-decision-list.txt\"\n",
    "OUTPUT_ANSWERS = r\"C:\\Users\\muge\\Dropbox\\GMU\\AIT 526\\Module 7\\line-data\\my-line-answers.txt\"\n",
    "\n",
    "def feature_set():\n",
    "    # Define feature functions\n",
    "\n",
    "    # Example:\n",
    "    def vote_feature(line):\n",
    "        return bool(re.search(r'vote', line)), 'phone'\n",
    "    yield vote_feature\n",
    "\n",
    "    def growth_feature(line):\n",
    "        return bool(re.search(r'growth', line)), 'phone'\n",
    "    yield growth_feature\n",
    "\n",
    "    # Add more feature functions as needed\n",
    "\n",
    "def probability(attribute, sense_text, other_text):\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "\n",
    "    for line in sense_text:\n",
    "        if line is not None and attribute(line)[0]:\n",
    "            count1 += 1\n",
    "\n",
    "    for line in other_text:\n",
    "        if line is not None and attribute(line)[0]:\n",
    "            count2 += 1\n",
    "\n",
    "    total_count = count1 + count2\n",
    "    prob1 = count1 / total_count\n",
    "    prob2 = count2 / total_count\n",
    "\n",
    "    try:\n",
    "        ratio = math.log10(prob1 / prob2)\n",
    "    except ZeroDivisionError:\n",
    "        ratio = 1\n",
    "\n",
    "    with open(OUTPUT, 'a+') as output:\n",
    "        output.write(f'{attribute.__name__}\\t{ratio}\\t{sense_text[0][1]}\\n')\n",
    "\n",
    "    logger.info(f'Attribute: {attribute.__name__}, Ratio: {ratio}, Sense: {sense_text[0][1]}')\n",
    "\n",
    "    return ratio\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info(\"Starting the decision-list.py script\")\n",
    "\n",
    "    with open(TRAIN_XML) as f:\n",
    "        data = f.read()\n",
    "\n",
    "    parser = BeautifulSoup(data, 'xml')\n",
    "\n",
    "    attribute_list = []\n",
    "\n",
    "    # Create an attribute list by identifying patterns from line-train.xml and associate attributes with sense\n",
    "    for feature in feature_set():\n",
    "        attribute_list.append(feature)\n",
    "\n",
    "    textsense1 = []\n",
    "    textsense2 = []\n",
    "\n",
    "    # Read the XML file into training argument\n",
    "    for instance in parser.find_all('instance'):\n",
    "        if instance.answer['senseid'] == 'phone':\n",
    "            for tag in instance.find_all('s'):\n",
    "                string = tag.string\n",
    "                textsense1.append(string)\n",
    "        else:\n",
    "            for tag in instance.find_all('s'):\n",
    "                string = tag.string\n",
    "                textsense2.append(string)\n",
    "\n",
    "    # Calculate probability for each attribute in the corpus\n",
    "    for attribute in attribute_list:\n",
    "        probability(attribute, textsense1, textsense2)\n",
    "\n",
    "    # Sort the attributes accordingly based on their probability scores and create a decision list\n",
    "    attribute_list.sort(key=lambda attribute: probability(attribute, textsense1, textsense2))\n",
    "\n",
    "    phone_count = len(parser.find_all(senseid=\"phone\"))\n",
    "    product_count = len(parser.find_all(senseid=\"product\"))\n",
    "    default_sense = 'phone' if phone_count > product_count else 'product'\n",
    "\n",
    "    with open(TEST_XML) as y:\n",
    "        data = y.read()\n",
    "\n",
    "    parser = BeautifulSoup(data, 'xml')\n",
    "\n",
    "    # Read the XML file into testing argument\n",
    "    for instance in parser.find_all('instance'):\n",
    "        context = tuple(\n",
    "            tag.string for tag in instance.find_all('s')\n",
    "            if tag.string is not None\n",
    "        )\n",
    "\n",
    "        sense = None\n",
    "\n",
    "        # Read the XML file based on the tag instance and read the context\n",
    "        # Perform search on a particular attribute in the context\n",
    "        for line in context:\n",
    "            for attribute in attribute_list:\n",
    "                if attribute(line)[0]:\n",
    "                    sense = attribute(line)[1]\n",
    "                    break\n",
    "\n",
    "        # If a particular attribute is matched in the attribute list, assign the associated sense\n",
    "        # If no match is found, assign the default sense (Phone)\n",
    "        if sense is None:\n",
    "            sense = default_sense\n",
    "\n",
    "        id_num = instance['id']\n",
    "        with open(OUTPUT_ANSWERS, 'a+') as output_check:\n",
    "            output_check.write(f'<answer instance=\"{id_num}\" senseid=\"{sense}\"/>\\n')\n",
    "\n",
    "        # Print the output in the same standard as the gold standard file\n",
    "        print(f'<answer instance=\"{id_num}\" senseid=\"{sense}\"/>')\n",
    "\n",
    "    logger.info(\"Finished running the decision-list.py script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea8935-e487-4657-83cf-d1b2f34dff40",
   "metadata": {},
   "source": [
    "#### scorer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d34af3-5619-4ad2-850b-775c40737101",
   "metadata": {},
   "source": [
    "##### Algorithm:\n",
    "\n",
    "1. Set up logging and file paths.\n",
    "2. Read the output file's content and add it to the f1 list.\n",
    "3. Divide each line of f1 at:\" and add the key-value pairs that result to the var1 list.\n",
    "4. Make an empty dictionary called predicted and fill it with the key-value pairs from var1.\n",
    "5. After removing the values from the predicted dictionary, create the predicted_list.\n",
    "6. Open the key file and add the information to the f2 list.\n",
    "7. Divide each line of f2 at:\" and add the key-value pairs that result to the var2 list.\n",
    "8. Create the key-value pairs from var2 and place them in the empty dictionary observed.\n",
    "9. After removing the values from the observed dictionary, create the observed_list.\n",
    "10. Using the observed_list and predicted_list, create a ConfusionMatrix object (cm).\n",
    "11. Set the counter variable x to zero.\n",
    "12. Go through the lists of predictions and observations repeatedly, increasing x for each pair that matches.\n",
    "13. Divide x by the length of the predicted_list, then multiply the result by 100 to find the accuracy.\n",
    "14. Print the confusion matrix and the accuracy matrix (cm).\n",
    "15. Update the logging to reflect the script's completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70650221-1f39-4d67-a0c6-85f7d1d1247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier is: 42.857142857142854 \n",
      "\n",
      "Confusion Matrix:                       |       |\n",
      "                     |     s |\n",
      "                     |     e |\n",
      "                     |  s  n |\n",
      "                     |  e  s |\n",
      "                     |  n  e |\n",
      "                     |  s  i |\n",
      "                     |  e  d |\n",
      "                     |  i  = |\n",
      "                     |  d  \" |\n",
      "                     |  =  p |\n",
      "                     |  \"  r |\n",
      "                     |  p  o |\n",
      "                     |  h  d |\n",
      "                     |  o  u |\n",
      "                     |  n  c |\n",
      "                     |  e  t |\n",
      "                     |  \"  \" |\n",
      "                     |  /  / |\n",
      "                     |  >  > |\n",
      "---------------------+-------+\n",
      "   senseid=\"phone\"/> | <.>72 |\n",
      " senseid=\"product\"/> |  .<54>|\n",
      "---------------------+-------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run %%writefile scorer.py to write and save scorer.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='scorer-log.txt', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting the scorer.py script\")\n",
    "\n",
    "    output_file = r\"C:\\Users\\muge\\Dropbox\\GMU\\AIT 526\\Module 7\\line-data\\my-line-answers.txt\"\n",
    "    key_file = r\"C:\\Users\\muge\\Dropbox\\GMU\\AIT 526\\Module 7\\line-data\\line-answers.txt\"\n",
    "\n",
    "    # Read and process the predicted answers\n",
    "    with open(output_file) as file:\n",
    "        f1 = [line.rstrip('\\n') for line in file]\n",
    "        var1 = [i.split(':\"', 1) for i in f1 if ':\"' in i]  # Ensure split is valid\n",
    "        predicted = {}\n",
    "\n",
    "    for a in range(len(var1)):\n",
    "        key = var1[a][0]\n",
    "        value = var1[a][1]\n",
    "        predicted[key] = value\n",
    "\n",
    "    predicted_list = [predicted[v] for v in predicted if v in predicted]\n",
    "\n",
    "    # Read and process the observed answers\n",
    "    with open(key_file) as myf1:\n",
    "        f2 = [line.rstrip('\\n') for line in myf1]\n",
    "        var2 = [i.split(':\"', 1) for i in f2 if ':\"' in i]  # Ensure split is valid\n",
    "        observed = {}\n",
    "\n",
    "    for a in range(len(var2)):\n",
    "        key = var2[a][0]\n",
    "        value = var2[a][1]\n",
    "        observed[key] = value\n",
    "\n",
    "    observed_list = [observed[v] for v in observed if v in observed]\n",
    "\n",
    "    # Debugging output\n",
    "    logger.info(f\"Length of predicted_list: {len(predicted_list)}\")\n",
    "    logger.info(f\"Length of observed_list: {len(observed_list)}\")\n",
    "\n",
    "    if len(predicted_list) != len(observed_list):\n",
    "        logger.error(\"Lists have different lengths.\")\n",
    "        print(\"Error: Lists have different lengths.\")\n",
    "        return\n",
    "\n",
    "    # Calculate and print accuracy and confusion matrix\n",
    "    cm = ConfusionMatrix(observed_list, predicted_list)\n",
    "    correct = sum(1 for i in range(len(predicted_list)) if predicted_list[i] == observed_list[i])\n",
    "    accuracy = (correct / len(predicted_list)) * 100\n",
    "\n",
    "    print('Accuracy of the classifier is:', accuracy, '\\n\\nConfusion Matrix: ', str(cm))\n",
    "    logger.info(\"Finished running the scorer.py script\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70edf2-f88c-4538-969b-15260bf378aa",
   "metadata": {},
   "source": [
    "##### Create a log list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7843c79-38be-4919-aced-6727450341ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script execution logged successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to log the script execution details\n",
    "def log_execution(script_path):\n",
    "    # Get the directory of the script\n",
    "    script_dir = os.path.dirname(script_path)\n",
    "\n",
    "    # Create the log file path\n",
    "    log_file_path = os.path.join(script_dir, \"decision-list-log.txt\")\n",
    "\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Create a log message\n",
    "    log_message = f\"Script executed on {current_time}\\n\"\n",
    "\n",
    "    # Write the log message to the file\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(log_message)\n",
    "\n",
    "    print(\"Script execution logged successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the script filename is provided as an argument\n",
    "    if len(sys.argv) > 1:\n",
    "        script_file = sys.argv[1]\n",
    "\n",
    "        # Get the absolute path of the script file\n",
    "        script_path = os.path.abspath(script_file)\n",
    "\n",
    "        # Log the script execution\n",
    "        log_execution(script_path)\n",
    "    else:\n",
    "        print(\"decision-list-log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cad91-9004-483e-9468-a3b585c6beed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
